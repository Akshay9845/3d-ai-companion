# üé≠ Avatar Integration Guide

## Quick Start

1. **Test BECKY Model**: Visit `http://localhost:5173/becky-test.html`
2. **Test Lip Sync**: The system now includes real-time lip sync
3. **Check Console**: Watch for lip sync and animation logs

## Current Status

### ‚úÖ Implemented
- BECKY model integration
- Advanced character configuration system
- Real-time lip sync controller
- Facial expression mapping
- Animation state management
- Free TTS fallback system

### üöß In Progress
- Enhanced viseme generation
- Audio analysis integration
- Gesture mapping system

### ‚è≥ Planned
- Emotion detection module
- Advanced gesture generation
- Motion capture retargeting

## Architecture

```
Speech Input ‚Üí LipSync Controller ‚Üí Viseme Generation ‚Üí BECKY Animation
     ‚Üì              ‚Üì                    ‚Üì                    ‚Üì
Text Analysis ‚Üí Emotion Detection ‚Üí Facial Expressions ‚Üí Real-time Rendering
     ‚Üì              ‚Üì                    ‚Üì                    ‚Üì
Intent Analysis ‚Üí Gesture Generation ‚Üí Body Animation ‚Üí Complete Avatar
```

## Testing the System

1. **Basic Animation Test**:
   ```bash
   npm run dev
   # Visit http://localhost:5173
   # Try voice chat to see lip sync in action
   ```

2. **Lip Sync Test**:
   - Speak into microphone
   - Watch console for viseme generation logs
   - Observe mouth animation changes

3. **Model Test Page**:
   - Visit `http://localhost:5173/becky-test.html`
   - Click test buttons to verify features

## Next Steps

1. **Enhance Lip Sync**: Integrate with Resemble Lip Sync
2. **Add Emotion Detection**: Implement openSMILE integration
3. **Gesture System**: Add DiffuseStyleGesture support
4. **Performance Optimization**: Optimize for real-time performance

## Troubleshooting

- **Model not loading**: Check BECKY.glb file path
- **Lip sync not working**: Check console for LipSyncController errors
- **Audio issues**: Verify microphone permissions
- **Animation glitches**: Check animation state logs
